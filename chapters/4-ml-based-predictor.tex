%--------------------------------------
%	Chapter 4. ML Hit-Pair Predictor
%--------------------------------------


\doublespacing
\newpage
%\setcounter{section}{3}
%\section{The Compressed Pattern Space}
\chapter{Machine Learning Hit-Pair Predictor} 
\label{chapter-4}
% DONE


% This study was conducted in order to speed up the track seeding stage and reduce CPU time in the ATLAS fast tracking trigger algorithm.

When constructing graph networks for track reconstruction, one must first consider the ability to identify compatible edge connections to build track seeds. A beneficial step towards enhancing this process is to reduce the number of fake seeds constructed and hence increase the accuracy in predicting such compatible hit-pairs. As future upgrades to particle detectors will be problematic for the silicon tracking detectors where hit occupancy is the largest, it is essential that resource use is also reduced, whilst maintaining the capability to reconstruct tracks with minimal efficiency loss. This chapter presents a methodology to accomplish such a task. This work is presented in the Journal of Physics: Conference Series \cite{Lad_2023} and is implemented in the optimisation of the HLT ID track seeding software for ATLAS Run-3 and beyond \cite{Grandi:2728111, Long:2813981}. Section \ref{measurement-to-track-association} presents the development of a ML-based algorithm to predict if a pair of hits belong to the same track given input hit features, focusing on cluster width and inverse track inclination. The implementation of the trained predictor in the form of Look-Up Tables is presented in Section \ref{application-of-hit-pair-predictor}, alongside performance results including tracking efficiency and speed-up factor using simulated data is also discussed.


\section{Measurement to track association}
\label{measurement-to-track-association}

\subsection{Data Exploration and Feature Extraction}

Seeds constructed at the combinatorial stage of ATLAS track seeding software from the Run-2 geometry were used to extract hit-pairs to form a training dataset. Monte Carlo (MC) $t\bar{t}$ event samples with centre-of-mass energy $\sqrt{s}$ = 13 TeV at mean pile-up interaction multiplicity $< \mu >$ = 80 were used. Top quark simulation is often used for developing algorithms in tracking due to its many possible final states including electron, muon and $\tau$ leptons, as well as \textit{b, c} and up quarks. As the decay signature of a top quark is complex, the combinatorics of the constructed seeds are high. This indicates that a larger proportion of fakes will be present and provides a good description of the environment in high luminosity conditions.

The training is focused on Pixel detector layers, being closest to the beamline and having highest hit occupancy. An illustration of a seed in the ID pixel layers is shown in Figure \ref{fig:triplet-illustration}. These triplets are deconstructed into pairs of doublets which share a common middle spacepoint. For each seed, the inner doublet (defined as hit-pair 1 and 2) and outer doublet (defined as hit-pair 2 and 3) are extracted. For each hit-pair the minimum and maximum absolute inverse slope of the track, $|cot(\theta)|$, are calculated using $r$-$z$ coordinates and used as an input feature for training. $\theta$ is the angle of inclination of a hit-pair with respect to the $z$ axis. The longitudinal pixel cluster width, $w_{\eta}$, measured in the $\eta$ direction was also extracted, where $\eta$ is defined in Eq. \ref{eq:pseudorap}. The MC generated data in the [$|cot(\theta)|$, $w_{\eta}$] phase space behaves as a set of 1-dimensional distributions, each with discrete $w_{\eta}$. This characteristic is exploited to form an ensemble of predictors. 

The MC truth class for seeds and their corresponding hit-pairs were extracted from ATLAS track seeding and used as targets in training. Doublets with correct hit association were defined as truth 1, for which its hit-pairs belong to the same truth track. Conversely doublets with incorrect hit association defined as truth 0, for which its hit-pairs do not belong to the same track. Hit-pairs for the Pixel barrel and endcap are handled separately in order to build regional classifiers. The same methodology was used for both the barrel and endcap, presented in Section \ref{section:classifier-dev} and \label{application-of-hit-pair-predictor} is the procedure and the results for the barrel.


\begin{figure}[!htbp]
\centering
    \includegraphics[width=0.85\linewidth]{images/4-ml-based-predictor/triplet_illustation.png}
    \caption{Seed illustration in the $r$-$z$ plane (mm) of the ID. The inner doublet consists of hits (1, 2) and the outer doublet consists of hits (2, 3). The longitudinal pixel-cluster width $w_{\eta}$ (mm) is measured in the direction of $\eta$, where $\theta$ is the angle of inclination with respect to the $z$ axis.}
\label{fig:triplet-illustration}
\end{figure}


\subsection{Classifier Development}
\label{section:classifier-dev}

\subsubsection{Not-so-Naive Bayes}
% DONE

The basis of Bayes’ theorem \cite{naive-bayes} is used to build a classifier to discriminate between doublet classes, for both the barrel and endcap regions. Bayesian analysis is based on having a prior probability of belief of an outcome of an event and a likelihood probability, where naive Bayes’ assumes that the conditional probabilities of the independent variables are statistically independent. The final classification is produced by computing the posterior probability by combining both the prior beliefs and the likelihood, which then determines the most probable class label. Using Bayes’ theorem is advantageous in this data-driven setting, as prior knowledge of the behaviour of the system is known. The posterior probability $P(c|x)$ that a given data point x belongs to class c is defined as:

\begin{equation} \label{naive-bayes}
    P(c|x) = \frac{P(x|c)P(c)}{P(x)}
\end{equation}

$P(x|c)$ is the conditional likelihood, $P(c)$ is the class prior probability and $P(x)$ is the predictor prior probability, used for normalisation and calculated from the number of data points belonging to class $c$.

Bayes' theorem is implemented using a generative model for each class. This was achieved by computing the likelihood function via a Kernel Density Estimate (KDE) for each of the 1-dimensional $\tau$ distributions, forming a set of generative Bayesian classifiers. This method removes the 'naive' element and performs the same classification with a more sophisticated generative model for each class.

\subsubsection{Kernel Density Estimation}
% DONE

KDE is a non-parametric approach to estimate the probability density function of a random variable. The idea is that a kernel function is defined and centred on each data point in the sample. The sum of these functions together forms the kernel density estimate. The kernel density is defined as:
    
\begin{equation} \label{eq2}
    \hat{f}(x) = \frac{1}{Nh}  \sum_{i=1}^{N} K \left( \frac{x - x_i}{h} \right)
\end{equation}

where $K(x)$ is the kernel function, typically a smooth, symmetric and non-negative function, $h > 0$ is the smoothing bandwidth that controls the amount of smoothing applied to the function and N is the number of sample points used for normalisation \cite{kde}. The KDE must be normalised in order to represent a probability density. For this study the Gaussian kernel function is implemented to approximate the probability density at each data point in the sample. One advantage of using KDE is that it provides a more flexible estimator parameterised by $h$. The Gaussian kernel is defined as:
    
\begin{equation} \label{eq3}
    K(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}
\end{equation}

The choice of bandwidth is important, as increasing the bandwidth too high results in a smooth distribution where granular information is lost (over-smoothing). When using a bandwidth that is too small, this can lead to narrow peaks in close proximity to each other, resulting in a very noisy distribution (under-smoothing). There are several methods to determine the optimum bandwidth discussed in \cite{bandwidth-selection-methods}, many of which show similar properties. The method used in this study was the so-called \textit{Silverman's rule of thumb}, which works only for 1-dimensional data. Silverman's rule finds the bandwidth that minimizes the mean integrated squared error assuming that the data is Gaussian and a Gaussian kernel was used.

\subsection{Classifier Training}

% talk about as many results as possible, i.e. roc auc

% training:
% A discrete 1-dimensional nature is observed increasing in increments of 0.2 mm, as a direct result of varying permutations of ‘standard’ and ‘long’ pixels in cluster width calculation, where each 1-dimensional band was independently trained and tuned to yield a true positive rate of 0.95. A similar procedure was executed for training and predicting doublet hit association for pixel-endcaps doublets using truth from Monte Carlo 13 TeV ����̅ <��> = 80 samples. This study was conducted in order to speed up the track seeding stage and reduce CPU time in the ATLAS fast tracking trigger algorithm.


%Figure \ref{fig:1-dimensional-classifier-training} shows distributions of $\rvert cot(\theta)\rvert$ for Pixel barrel hit pairs in the ATLAS pixel detector, where $\theta$ is the inclination angle of the doublet with respect to the $z$-axis. from t ̄t Monte Carlo 13 TeV with mean pile-up interaction multiplicity of <μ> = 80. Shown are pixel-barrel doublets from triplets constructed at the combinatorial stage in ATLAS track seeding. These triplets are formed from pairs of doublets which share a common spacepoint where that shared middle spacepoint consists of pixel clusters with wη ≤ 0.4 mm, where wη is the cluster width measured in the η direction. Shown are the distributions for doublets with hits correctly associated to corresponding truth particles by the tracking algorithms, for which its doublet spacepoints belong to the same track and also shown are doublets that have hits incorrectly associated, for which its spacepoints do not belong to the same track. The data was used to train a Machine Learning classifier to predict whether a doublet of spacepoints has correct hit association and hence belong to the same track corresponding to truth particles, or incorrect hit association, using the input hit features of wη and the absolute inverse track inclination |cot(θ)|. This study was conducted in order to speed up the track seeding stage and reduce CPU time in the ATLAS fast tracking trigger algorithm.

% roc curve:
%Shown is the Receiver Operating Characteristic (ROC) curve indicating the rates of false positive and true positive of pixel-barrel doublets from the ATLAS pixel detector to tracks corresponding to truth particles, for spacepoints with wη ≤ 0.4 mm, where wη is the cluster width measured in the η direction, using a Machine Learning (ML) classifier to predict whether a doublet of spacepoints belong to the same track and hence defined as having correct hit association, or have incorrect hit association. The classifier was trained using pixel-barrel doublets from Monte Carlo 13 TeV t ̄t <μ> = 80 samples. Each pair of false positive and true positive rates correspond to a prediction probability, which can be used as a tuning parameter. The classifier’s predictions were adjusted using the prediction probability derived from the ROC curve which would yield a true positive rate of 0.95. The Area Under the Curve (AUC) is a measure of the ability of the classifier to distinguish between correct and incorrect hit association classes and is in the range 0.0 ≤ AUC ≤ 1.0, where AUC = 1 corresponds to perfect classification. The AUC achieved by the ML classifier shown was AUC = 0.79. Also shown is the ‘no skill’ classifier result with AUC = 0.5, which cannot discriminate between correct or incorrect hit association classes and would predict a random class in all cases with 50% probability for each class. A similar procedure was executed for training a model to determine whether spacepoints in pixel-endcap doublets belonged to the same track, using truth from Monte Carlo 13 TeV t ̄t <μ> = 80 samples. This study was conducted in order to speed up the track seeding stage and reduce CPU time in the ATLAS fast tracking trigger algorithm.

\begin{figure}[!htbp]
\centering
    \begin{subfigure}[a]{0.9\textwidth}
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/histo.pdf}
        \caption{$\lvert cot(\theta) \rvert$ distributions for Pixel barrel hit pairs with $w_{\eta} \leq 0.4$ mm }
        \label{fig:truth-histo}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.9\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/roc.pdf}
        \caption{ROC curve for Pixel barrel hit pairs with $w_{\eta} \leq 0.4$ mm }
        \label{fig:roc-curve}
    \end{subfigure}
\caption{(a) $\lvert cot(\theta) \rvert$ for Pixel barrel hit pairs in the ATLAS Pixel detector, where $\theta$ is the inclination angle of the hit pair with respect to the $z$-axis. (b) The corresponding Receiver Operating Characteristic (ROC) curve for the classifier trained on the data shown in (a). The curve indicates the rates of false positive and true positive of Pixel barrel hit pairs to tracks corresponding to truth particles.}
\label{fig:1-dimensional-classifier-training}
\end{figure}


\subsection{Probability Calibration}

% READ THIS:
% https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/
% https://scikit-learn.org/stable/modules/calibration.html

KDE Calibration curve for pixel-barrel doublets with 0 - weta - 0.4. We can evaluate how well our model \& the predicted probabilities are calibrated. Calibration curve (reliability diagram) is generated for each weta bands, by analysing uncalibrated model, isotonic \& sigmoid calibration. Models are evaluated based on their Brier score (mean squared error). Uncalibrated KDE classifier (blue line) yields lowest error - no calibration needed

\begin{figure}[!htbp]
% \begin{figure}[htbp]
\centering
\includegraphics[width=0.88\linewidth]{images/4-ml-based-predictor/calibration.png}
\caption{Probability Calibration/ Reliability curve indicating whether probability calibration was needed....}
\label{fig:calibration}
\end{figure}


\subsection{Classifier Predictions and Evaluation}

% TODO: make sure to go through all plot captions on HLT public results page for ATLAS Simulation Preliminary plots because there are explanation sentences in there for this chapter

\begin{figure}[!htbp]
\centering
    \begin{subfigure}[a]{0.91\textwidth}
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/scatter_kde_predictions.pdf}
        \caption{Classifier predictions for Pixel barrel hit pairs plotted as $\lvert cot(\theta) \rvert$ vs. $w_{\eta}$}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.91\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/triplet_eff_metrics.pdf}
        \caption{Seed selection efficiency and total rejection efficiency}
    \end{subfigure}
\caption{(a) Predicted classification of Pixel barrel hit pairs from the ATLAS Pixel detector, trained using a set of ML classifiers to distinguish hit pairs matched to tracks corresponding to truth particles. Hit pair features used in training: $\lvert cot(\theta) \rvert$, where $\theta$ is the inclination angle of the hit pair to the z-axis and the Pixel cluster width $w_{\eta}$. The corresponding seed selection efficiency and total rejection efficiency are shown in (b). Errors shown here are purely statistical.}
\label{fig:predictions-pixel-barrel-and-triplet-efficiencies}
\end{figure}



%The seed selection efficiency is defined as the proportion of seeds with both its constituent doublet pairs classified as correctly associated, out of all correctly associated seeds corresponding to Monte Carlo truth from ATLAS tracking algorithms, and the total seed rejection efficiency considers the proportion of rejected seeds, thereby providing an estimate of the total CPU time saved. The lower efficiency and corresponding reduced purity around ��! ~ 2.0 mm is due to the transition between the barrel and endcap pixel detector. Errors shown here are purely statistical.



\section{Application of hit-pair predictor}
\label{application-of-hit-pair-predictor}

\subsection{Look-Up Table Generation}

The classifier predictions are used as input in the Fast Tracking trigger stage/algorithm.

Classifier predictions are converted into Look-Up Tables (LUT) such that the acceptance region can be fed into the FTF. Using a predefined LUT is a much more efficient procedure than computing class label on the fly and it is very low cost to store in memory. It consists of binning both the W eta axes (45 bins between 0.0 - 3.0) and the $\tau$ axes (30 bins between 0.0 - 3.0), recording the bin numbers to accept. These divisions were chosen such to compare with the current estimation, referred to as strict LUT.

\subsubsection{Morphological Filtering}

%Classifier predictions for the pixel barrel (Figure 4) and endcap regions were implemented directly into the ATLAS HLT Fast Tracking to reduce computational overheads. This was achieved by converting the predefined acceptance region into a Look-Up Table (LUT) using a common image processing technique known as Morphological Filtering [6].

An ensemble approach was taken combining the strict LUT and KDE predictions. Morphological filtering was then applied to achieve a smoothed structure. Morphological filtering is an image processing technique whereby non-linear transformations are applied to the binary matrix of an image, altering the features. Such non-linear operations include dilation and erosion. Dilation enlarges bright regions and shrinks dark regions, whereas erosion does the inverse of this. A combination of dilation and erosion was applied to the ensemble LUT via rectangular structuring elements, in order to encourage horizontal
extrapolation of the acceptance region. The binned predictions from the KDE classifiers and smoothed LUTs are shown in Figures 9 and 10; orange representing acceptance regions and blue rejection regions.
Referring to 9a, KDE predictions for the barrel coincide well with the ’linear corridor’ estimation from the strict LUT. Whereas a V-shaped LUT is obtained for the endcap region.

% \subsubsection{ML Filtering Modes}




\subsection{Performance Evaluation}

The full scan ID efficiencies as a function of MC truth track $\eta$ and $p_T$ for the \texttt{Fast tracking} trigger stage, are shown in Figures \ref{fig:efficiencies-ml-hit-pair-predictor-eta} and \ref{fig:efficiencies-ml-hit-pair-predictor-pt}. The nominal seeding approach is compared with the application of ML filtering within the Pixel detector. The nominal seeding achieved an average tracking efficiency of 95\% with respect to MC truth tracks. The application of ML filtering at $\langle \mu \rangle$ = 80, achieved an average tracking efficiency of 93.9\% and the speed-up factor was observed to be a factor of 2.3. The main loss in efficiency is observed at regions of large $\lvert \eta \rvert$, due to the transition between the barrel and endcap Pixel detector. Overall, there is little deviation from the standard trigger seeding with application of ML extensions.


\begin{figure}[!htbp]
\centering
    \begin{subfigure}[a]{0.86\textwidth}
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/efficiency_eta.pdf}
        \caption{Efficiency vs. MC truth track $\eta$}
    \label{fig:efficiencies-ml-hit-pair-predictor-eta}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.86\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/4-ml-based-predictor/efficiency_pT.pdf}
        \caption{Efficiency vs. MC truth track $p_{\mathrm{T}}$}
    \label{fig:efficiencies-ml-hit-pair-predictor-pt}
    \end{subfigure}
\caption{Tracking efficiencies as a function of track parameters, for $p_{T}$ > 3 GeV for the ATLAS full detector tracking with $t\overline{t}$ Monte Carlo 13 TeV and mean pile-up interaction multiplicity of $\langle \mu \rangle$ = 80. The data points show the efficiency when using machine learning extensions in the seed building stages of the fast tracking trigger in the ATLAS pixel detector, prior to the track fitting. The dashed line shows the efficiency of the standard trigger seeding with no application of machine learning extensions. The errors shown are purely statistical \cite{public-hlt}. }
\label{fig:efficiencies-ml-hit-pair-predictor}
\end{figure}



\subsubsection{CPU Time Comparison}
% DONE

% TODO: know how the speed-up factor was measured - within an isolated testbed environment, with as little other processes occuring at the same time. Measuring the fastest time, and hence the greatest speed-up factor, not the average! - this is important here

Table \ref{tab:cpu} summarises the breakdown in speed-up factors achieved at various stages within the \texttt{Fast Tracking} trigger algorithm, with the application of the trained LUT for the Pixel region. The total speed-up factor achieved in the full detector with application of ML extensions at $\langle \mu \rangle$ = 80 was observed to be 2.3. The greatest saving in CPU time is achieved during the \texttt{Seed Processing} stage, as a direct result of the significant reduction in the number of seeds. The average number of seeds processed for a given region of interest for the standard tracking is $O(10^{4})$, whereas with the introduction of ML filtering for pixel seeds, approximately 78\% fewer seeds were observed. This significant reduction in CPU time does not only benefit the \texttt{Seed Processing} stage of the combinatorial track following algorithm in ATLAS, but also propagates to the \texttt{Track Fitting} stage.

\begin{table}[htb!]
\caption{Performance of the ATLAS full detector tracking with MC 13 TeV $t\bar{t}$ samples at $<\mu> = 80$, with the application of ML extensions for filtering on pixel detector hit-pairs in the \texttt{Fast Tracking} trigger stage \cite{public-hlt}. The total speed-up factor and breakdown of speed-ups at different stages of the \texttt{Fast Tracking} trigger algorithm are presented, each speed-up is presented with respect to the standard trigger seeding where no ML extensions are applied.}
\begin{center}
\begin{tabular}{llll}
\toprule
Total Speed-up Factor & Seed Generation & Seed Processing & Track Fitting \\
\hline
2.3 & 1.3 & 3.3 & 1.5 \\ 
\bottomrule
\end{tabular}
\end{center}
\label{tab:cpu}
\end{table}

\subsubsection{Changing Pileup Conditions}
% DONE

Table \ref{tab:pileup} summarises the relative efficiency loss and relative speed-up factor, with application of ML extensions for the ATLAS pixel detector in various mean pile-up interaction multiplicities $<\mu>$. The absolute loss in average tracking efficiency and the total speed-up factor for seeded track finding in the ATLAS pixel detector is presented with respect to the standard trigger seeding where no machine learning extensions were applied. A general trend is observed whereby the speed-up factor increases as $<\mu>$ increases with minimal loss in efficiency. At $<\mu>$ = 80 the efficiency loss observed was 1.1\%, which was acceptable by the ID trigger performance requirements at the time of writing.


\begin{table}[!htbp]
\caption{Performance of the ATLAS full detector tracking with MC 13 TeV $t\bar{t}$ samples at $<\mu>$ = 40, 60 and 80, with the application of ML extensions for filtering on pixel detector hit-pairs in the \texttt{Fast Tracking} trigger stage prior to the track fitting \cite{public-hlt}. The absolute loss in average tracking efficiency and the total speed-up factor for seeded track finding in the ATLAS pixel detector are presented with respect to the standard trigger seeding where no ML extensions were applied. The efficiency loss is mainly observed at large $|\eta|$. The statistical uncertainties in efficiencies are $O(10^{-3})$, hence are not quoted.}
\begin{center}
\begin{tabular}{ccc}
\toprule
$<\mu>$ & Efficiency Loss (\%) & Total Speed-up Factor  \\
\hline
40 & 0.7 & 1.6 \\
60 & 0.7 & 2.1 \\
80 & 1.1 & 2.3 \\
\bottomrule
\end{tabular}
\end{center}
\label{tab:pileup}
\end{table}


\section{Other Approaches}
\subsection{Multiple Acceptance Regions}
% DONE

When training on varying permutations of train and test data sets, a second acceptance region was frequently predicted for some of the 1-dimensional distributions where Pixel barrel hit-pairs possess low cluster width and high track inclination. This second region is highlighted in Figure \ref{fig:multiple-acceptance} which shows the KDE-based classifier's predictions for a particular train and test permutation. The hit-pairs predicted as belonging to class 1 having correct hit association for $w_{\eta} = 0.6$mm and $w_{\eta} = 1.0$mm appear at the tail ends of these distributions. These hits were isolated and their local cluster position in the $\eta$ direction was analysed. Approximately 60\% of hits possessed the largest absolute local cluster position and this was observed for each occurrence of a second acceptance region appearing at low cluster-width and high track inclination. This corresponds to hits being located at the extremes of the barrel module since its dimensions are approximately 20mm $\times$ 60mm \cite{pixel-module-dimensions} and strongly suggests that the second acceptance region had originated from module edge Pixels. Further investigation would be needed whereby these spacepoints would be handled separately or accepted by default. One reason for this is, as morphological smoothing is applied uniformly to an image, this dilation may interact with the general shape of the main acceptance region for the barrel and would have the potential to accept a greater proportion of fakes.

\begin{figure}[!htbp]
% \begin{figure}[htbp]
\centering
\includegraphics[width=0.9\linewidth]{images/4-ml-based-predictor/Multiple_acceptance_regions.pdf}
\caption{KDE-based classifier predictions for the Pixel barrel hit pairs. Multiple acceptance regions are observed at large track inclination for $w_{\eta} = 0.6$mm and $w_{\eta} = 1.0$mm, circled in red.}
\label{fig:multiple-acceptance}
\end{figure}


\subsection{Support Vector Machine}
% DONE

% See this website for further explanation 
% https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47
% multi class classification: one-to-rest
% https://towardsdatascience.com/multiclass-classification-with-support-vector-machines-svm-kernel-trick-kernel-functions-f9d5377d6f02

Another supervised learning algorithm investigated was the Support Vector Machine (SVM) \cite{svm}. The objective of a SVM classifier is to find a hyperplane (known as a decision boundary) in a N-dimensional space (where N is the number of features) that distinctly classifies the data points and is typically used in binary classification. The optimal decision boundary is one which maximizes the margins between both classes. This provides some reinforcement that unseen data points can be classified with more confidence. For non-linear decision boundaries, the SVM uses the so-called \textit{kernel trick} to project the data into a higher dimensional space to find a plane where the data is linearly separable. 

The SVM classifier was directly applied to the data in the phase space of  [$|cot(\theta)|$, $w_{\eta}$], however in this instance the observed discrete nature affected the mechanics of the classifier and its ability to determine a decision boundary. Therefore, a prior step to training the SVM was to apply Principal Component Analysis (PCA). PCA is commonly used as a dimensionality reduction technique \cite{pca}, whereas it was applied here to remove the ordinal nature of the cluster widths. By doing so, the data was transformed into a continuous 2-dimensional phase space, where the variance of the truth 1 class is maximal along the first principal component axis. A hyperparameter sweep of various kernels was executed using cross-validation and the polynomial kernel of third degree, with hyperparameters $C=0.75$ and $\gamma=0.05$, was found to produce the highest TPR of 95\%. The predictions of the PCA-SVM classifier on Pixel barrel data and the corresponding decision boundary is shown in Figure \ref{fig:barrel-svm-pca}. The shaded orange-red region indicates predicted hit-pairs with correct association, whereas the shaded blue region indicates predicted hit-pairs with incorrect association. The corresponding data points also reflect class predictions.  

% \begin{figure}[!htbp]
\begin{figure}[htbp]
\centering
\includegraphics[width=0.87\linewidth]{images/4-ml-based-predictor/barrel-svm-pca.png}
\caption{PCA transform and SVM classifier applied to Pixel barrel hit pairs. The SVM decision boundary predictions are illustrated, where the black dotted line represents the threshold value of 0.40 yielding a TPR of 95\%. Predicted hit-pairs with correct association are illustrated by diamonds and predicted hit pairs with incorrect association are illustrated with +. The SVM kernel used for the classifier was a polynomial degree 3 kernel with hyperparameters $C=0.75$ and $\gamma=0.05$. The 1st principal component indicates the axis of largest variance within the class with correct hit association doublet class.}
\label{fig:barrel-svm-pca}
\end{figure}

By applying a combination of Principal Component Analysis (PCA) and SVM, the classifier was able to separate the two classes well. However the corresponding FPR obtained was 82\% and the ROC AUC was 0.53, very similar to the no-skill classifier. Both of these metrics indicate that a large proportion of hit-pairs were incorrectly accepted by the model and hence this would increase the proportion of fake seeds constructed by downstream algorithms.

SVMs generally perform well, even when trained with imbalanced data sets. This coupled with the fact that a distinct decision boundary could be easily extracted and converted into a LUT would lead to less ambiguity in comparison to applying an extrapolation using morphological smoothing. However, there are key disadvantages by using a SVM rather than Bayes' theorem in this instance. The probabilistic information contained within each discrete 1 dimensional distribution of $w_{\eta}$ is lost, which is an important feature when tuning each individual distribution. Additionally, the SVM typically fits a continuous function for the decision boundary and hence may not be strict enough in certain regions. This factor is important when considering the proportion of fake seeds being accepted using a LUT generated from such a decision boundary. Due to these key differences in classifiers, this method was not pursued.


\subsection{Comparison with a Deep Learning Approach}

Comparison with outrunner algorithm (number 2 in TrackML) - deep learning methodoloy vs. our classic ML approach.
%At the end of this chapter, mention that a similar classifier was implemented to find pairs of hits for TrackML algorithm as well. Interestingly it also goes to a LUT input because this is the fastest way to do inference and implement this in any realistic detector setup, instead of training the classifier each time on the fly. Of course, for different geometrical setups or for particular signatures i.e. jets, the training would need to be done again specifically for that purpose.


\section{Conclusions}
%DONE

As the luminosity and collision rate increases during future upgrades of the LHC program, novel and precise tracking methodologies, as well as efficient use of computing power will become increasingly important in the selection of physics objects. Therefore, it is essential that resource use is reduced, whilst maintaining the ability to reconstruct tracks with minimal efficiency loss. 

The above work prsents the algorithms and techniques implemented to optimise the HLT ID track seeding software for ATLAS Run-3 and beyond, in order to reduce the number of fake seeds. The ML-based algorithm developed is used to predict if a pair of hits belong to the same track given input hit features of Pixel cluster width and inverse track inclination. It is encouraging to see that the application of the ML-based classifier for seed selection in the ATLAS ID has provided significant CPU savings on trained MC data at various pileup levels. The trained predictor in the form of a LUT yields 2.3$\times$ speed-up with minimal loss in efficiency (1.1\%) at $< \mu >$= 80 compared with the standard trigger tracking. 

The developed ML pipeline is advantageous for many reasons. It provides a flexible way to generate custom LUTs depending on the degree of efficiency required; the predictor can be trained to yield a desired TPR. This ML setup can also be used to generate a custom LUT for different geometrical setups, isolating different requirements for the barrel and endcap regions. This machinery can also provide ways to generate custom LUTs for particular decay signatures depending on the requirements. The fast lookup implementation bodes well in a realistic detector setup, instead of training the classifier each time on the fly. Overall, the reduction in fakes at an earlier stage in the HLT track seeding, ensures the reduction of bad seed propagation into downstream tracking stages and hence allows significant savings in CPU.

%i.e. jets, the training would need to be done again specifically for that purpose.

%. The use of different ML filtering modes applied to the triplets, can produce varying efficiencies (and speed up), where the three least redundant combinations are presented in this study. Additionally, proper training and tuning of the classifier can yield a required TPR, therefore allowing the flexibility in strictness.
